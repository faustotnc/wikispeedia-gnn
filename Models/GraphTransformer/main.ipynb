{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from urllib.parse import unquote\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GraphNorm\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from torch_geometric.nn import TransformerConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text data\n",
    "data = pd.read_csv(f\"../../data/full_text_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load links\n",
    "links = pd.read_csv(\"../../data/Wikispeedia/links.tsv\", sep=\"\\t\", names=[\"src\", \"tgt\"], skiprows=12)\n",
    "links[\"src\"] = links[\"src\"].map(lambda x: unquote(x))\n",
    "links[\"tgt\"] = links[\"tgt\"].map(lambda x: unquote(x))\n",
    "\n",
    "# Create adjacency matrix\n",
    "ordered_data_titles = data[\"title\"].tolist()\n",
    "src_indices = links[\"src\"].map(lambda x: ordered_data_titles.index(x))\n",
    "tgt_indices = links[\"tgt\"].map(lambda x: ordered_data_titles.index(x))\n",
    "A = torch.zeros((len(ordered_data_titles), len(ordered_data_titles)))\n",
    "A[src_indices, tgt_indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kt/8729r9s16_15cc905qks8zl40000gn/T/ipykernel_11384/3991216429.py:6: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  edge_features = A * coherence_graph\n"
     ]
    }
   ],
   "source": [
    "# Load coherence graph\n",
    "with open(\"../../data/coherence_graph.pkl\", 'rb') as handle:\n",
    "    coherence_graph = pickle.load(handle)\n",
    "\n",
    "# Combine coherence graph with base links\n",
    "edge_features = A * coherence_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kt/8729r9s16_15cc905qks8zl40000gn/T/ipykernel_11384/3588909332.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  node_static_embeddings = torch.tensor(node_static_embeddings, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# Load node embeddings\n",
    "with open(\"../../data/gpt4_embeddings.pkl\", 'rb') as handle:\n",
    "    obj = pickle.load(handle)\n",
    "    node_static_embeddings = obj[\"embeddings\"]\n",
    "    del obj\n",
    "node_static_embeddings = torch.tensor(node_static_embeddings, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user-extracted paths\n",
    "paths_data = pd.read_csv(f\"../../data/paths_no_back_links.tsv\", sep=\"\\t\")\n",
    "paths_data = paths_data[~(paths_data[\"rating\"].isna())]\n",
    "\n",
    "# Filter paths with at least four distinct pages\n",
    "paths_data = paths_data[paths_data[\"path\"].apply(lambda x: len(set(x.split(\";\"))) >= 4)]\n",
    "\n",
    "# Map titles to indices\n",
    "title_to_index = {unquote(title): idx for idx, title in enumerate(data['title'])}\n",
    "paths = paths_data['path'].apply(lambda path: [title_to_index[unquote(title)] for title in path.split(';')]).tolist()\n",
    "ratings = (paths_data['rating'] - 1).tolist()  # 0-indexed ratings\n",
    "\n",
    "# Binary ratings\n",
    "ratings = [1 if r > 1 else 0 for r in ratings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiahaoxu/Github/wikispeedia-gnn/.venv/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "class PathDataset(Dataset):\n",
    "    def __init__(self, paths, ratings, node_embeddings, edge_features):\n",
    "        self.paths = paths\n",
    "        self.ratings = ratings\n",
    "        self.node_embeddings = node_embeddings\n",
    "        self.edge_features = edge_features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        rating = self.ratings[idx]\n",
    "        nodes, edge_index, edge_weight = self.get_subgraph_edges(path)\n",
    "\n",
    "        x = self.node_embeddings[nodes]\n",
    "\n",
    "        data = Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_weight=edge_weight,\n",
    "            y=torch.tensor([rating], dtype=torch.long)\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    def get_subgraph_edges(self, path):\n",
    "        nodes = list(set(path))\n",
    "        node_to_idx = {node: idx for idx, node in enumerate(nodes)}\n",
    "        edges = []\n",
    "        edge_weights = []\n",
    "        for i in nodes:\n",
    "            for j in nodes:\n",
    "                weight = self.edge_features[i, j]\n",
    "                if weight > 0:\n",
    "                    edges.append([node_to_idx[i], node_to_idx[j]])\n",
    "                    edge_weights.append(weight)\n",
    "        if edges:\n",
    "            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "            edge_weight = torch.tensor(edge_weights, dtype=torch.float)\n",
    "        else:\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "            edge_weight = torch.tensor([], dtype=torch.float)\n",
    "        return nodes, edge_index, edge_weight\n",
    "\n",
    "# Create dataset\n",
    "dataset = PathDataset(paths, ratings, node_static_embeddings, edge_features)\n",
    "\n",
    "# Split dataset\n",
    "train_ratio = 0.85\n",
    "val_ratio = 0.05\n",
    "test_ratio = 0.1\n",
    "total_size = len(dataset)\n",
    "train_size = int(train_ratio * total_size)\n",
    "val_size = int(val_ratio * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 6\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8469, 1.1531])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts occurrences of each class\n",
    "class_counts = torch.bincount(\n",
    "    torch.tensor(ratings)[train_dataset.indices].to(torch.int64)\n",
    ")\n",
    "\n",
    "# Calculate weights as the inverse of class frequencies\n",
    "class_weights = 1.0 / class_counts.float()\n",
    "\n",
    "# Normalize the weights so that they sum to the number of classes\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import TransformerConv, global_mean_pool, GraphNorm\n",
    "\n",
    "class GraphTransformerModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes, heads=4, dropout=0.2):\n",
    "        super(GraphTransformerModel, self).__init__()\n",
    "        self.conv1 = TransformerConv(\n",
    "            in_channels, hidden_channels // heads, heads=heads, edge_dim=1, dropout=dropout)\n",
    "        self.norm1 = GraphNorm(hidden_channels)\n",
    "        self.conv2 = TransformerConv(\n",
    "            hidden_channels, hidden_channels // heads, heads=heads, edge_dim=1, dropout=dropout)\n",
    "        self.norm2 = GraphNorm(hidden_channels)\n",
    "        self.classifier = torch.nn.Linear(hidden_channels, num_classes)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weight\n",
    "\n",
    "        # Reshape edge_weight to [num_edges, 1]\n",
    "        if edge_weight is not None:\n",
    "            edge_attr = edge_weight.view(-1, 1)\n",
    "        else:\n",
    "            edge_attr = None\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = self.norm2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch=data.batch)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x  # Return raw logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 164.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6801, Val Acc: 0.6190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:21<00:00, 167.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.6763, Val Acc: 0.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 164.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 0.6766, Val Acc: 0.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 160.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 0.6776, Val Acc: 0.6321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 166.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 0.6733, Val Acc: 0.6376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 162.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 0.6733, Val Acc: 0.6198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 154.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss: 0.6741, Val Acc: 0.6244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 165.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss: 0.6769, Val Acc: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:24<00:00, 149.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss: 0.6741, Val Acc: 0.5533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 165.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.6734, Val Acc: 0.6012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 164.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Loss: 0.6712, Val Acc: 0.6128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 163.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Loss: 0.6719, Val Acc: 0.6314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 161.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Loss: 0.6730, Val Acc: 0.5734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 162.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Loss: 0.6727, Val Acc: 0.6221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:25<00:00, 143.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Loss: 0.6725, Val Acc: 0.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:31<00:00, 114.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Loss: 0.6738, Val Acc: 0.4807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:27<00:00, 132.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Loss: 0.6739, Val Acc: 0.6267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:29<00:00, 122.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Loss: 0.6742, Val Acc: 0.6314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 158.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Loss: 0.6736, Val Acc: 0.6151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 159.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss: 0.6730, Val Acc: 0.4204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 156.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Loss: 0.6724, Val Acc: 0.6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 159.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Loss: 0.6729, Val Acc: 0.5355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 156.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Loss: 0.6728, Val Acc: 0.5471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 154.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Loss: 0.6721, Val Acc: 0.5170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 155.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Loss: 0.6728, Val Acc: 0.5781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 158.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026, Loss: 0.6728, Val Acc: 0.6221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 161.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027, Loss: 0.6722, Val Acc: 0.6267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 155.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028, Loss: 0.6741, Val Acc: 0.6267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 155.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029, Loss: 0.6727, Val Acc: 0.4204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 154.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030, Loss: 0.6735, Val Acc: 0.6329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 159.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 031, Loss: 0.6724, Val Acc: 0.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 156.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 032, Loss: 0.6727, Val Acc: 0.5046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 155.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 033, Loss: 0.6730, Val Acc: 0.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 162.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 0.6737, Val Acc: 0.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:21<00:00, 171.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 035, Loss: 0.6734, Val Acc: 0.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 162.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 036, Loss: 0.6718, Val Acc: 0.5680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 164.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 037, Loss: 0.6732, Val Acc: 0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 160.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 038, Loss: 0.6704, Val Acc: 0.6445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 162.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 039, Loss: 0.6717, Val Acc: 0.4652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 159.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 040, Loss: 0.6728, Val Acc: 0.5587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 164.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 041, Loss: 0.6719, Val Acc: 0.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:21<00:00, 169.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 042, Loss: 0.6723, Val Acc: 0.6051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:24<00:00, 148.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 043, Loss: 0.6727, Val Acc: 0.6422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 157.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 044, Loss: 0.6736, Val Acc: 0.6283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 157.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 045, Loss: 0.6727, Val Acc: 0.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:23<00:00, 156.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 046, Loss: 0.6727, Val Acc: 0.6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 160.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 047, Loss: 0.6708, Val Acc: 0.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 163.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 048, Loss: 0.6719, Val Acc: 0.6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:22<00:00, 161.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 049, Loss: 0.6724, Val Acc: 0.6074\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "model = GraphTransformerModel(\n",
    "    in_channels=node_static_embeddings.shape[1],\n",
    "    hidden_channels=128,\n",
    "    num_classes=2,\n",
    "    heads=4,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in tqdm(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == data.y).sum().item()\n",
    "            total += data.num_graphs\n",
    "    return correct / total\n",
    "\n",
    "best_val_acc = 0\n",
    "for epoch in range(1, 50):\n",
    "    loss = train()\n",
    "    val_acc = evaluate(val_loader)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), '.best_binary_model.pth')\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kt/8729r9s16_15cc905qks8zl40000gn/T/ipykernel_11384/2583839261.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('.best_binary_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6263\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load('.best_binary_model.pth'))\n",
    "\n",
    "test_acc = evaluate(test_loader)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def conf_matrix(model, dataset_loader):\n",
    "    # Pass the testing loader through the model\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataset_loader:\n",
    "            batch = batch.to(device)  # Move batch to the same device as the model\n",
    "            logits = model(batch)  # Pass the entire batch to the model\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            labels = batch.y.cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "# Assuming your trained model is named 'model' and your DataLoader is 'test_loader'\n",
    "conf_matrix(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
